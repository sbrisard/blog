# -*- coding: utf-8; fill-column: 79 -*-
#+SETUPFILE: "../include/css-1.org"
#+SETUPFILE: "../include/mathjax.org"
#+TITLE: On the periodic-plus-smooth decomposition of an image, part 3: the energy as a quadratic form
#+DATE: [2018-01-15 Mon]
#+LINK: moisan2011   https://doi.org/10.1007/s10851-010-0227-1
#+LINK: sb-blog-prev ./On_the_periodic-plus-smooth_decomposition_of_an_image-02.org
#+LINK: sb-blog-next ./On_the_periodic-plus-smooth_decomposition_of_an_image-04.org
#+LINK: sb-blog-data-dir ./On_the_periodic-plus-smooth_decomposition_of_an_image/
#+PROPERTY: header-args:ipython :session :eval no-export :exports both

In the [[sb-blog-prev:][previous instalment]] of this series, we introduced the
periodic-plus-smooth decomposition of an image as a pair of images which
minimizes an energy functional. The purpose of this post is to show that this
energy is in fact a quadratic functional, the minimization of which therefore
amounts to solving a linear problem.

In this post, it will be convenient to regard images as vectors. Given two
$m\times n$ images $u$ and $v$, the scalar product $u\cdot v$ is then defined
as
\begin{equation*}
u\cdot v=\sum_{i=0}^{m-1}\sum_{j=0}^{n-1}u_{ij}v_{ij}.
\end{equation*}

Likewise, a linear operator $A$ over the space of $m\times n$ images is defined
as follows
\begin{equation*}
v=A\cdot u,\quad\text{with}\quad v_{ij}
=\sum_{k=0}^{m-1}\sum_{l=0}^{n-1}A_{ij,kl}u_{kl}.
\end{equation*}

According to Moisan ([[moisan2011:][2011]]), the total energy $E(p, s)$ of the
periodic-plus-smooth decomposition of an image $u=p+s$ is defined as the sum
$E(p, s)=E_\mathrm p'(p)+E_\mathrm s(s)$. The contributions $E_\mathrm p(p)$ of
the [[periodic-contrib][periodic component]] and $E_\mathrm s'(s)$ of the [[smooth-contrib][smooth component]] $s$ to the
total energy $E$ are analyzed separately below.

* Contribution of the periodic component <<periodic-contrib>>

The contribution to the total energy of the periodic component $p$ is defined
by Moisan ([[moisan2011:][2011]]) as follows (see also [[sb-blog-prev:][previous post]])
\begin{equation}
\label{eq:1}
E_\mathrm p(p)=2\sum_{i=0}^{m-1}(p_{i, n-1}-p_{i, 0})^2
+2\sum_{j=0}^{n-1}(p_{m-1, j}-p_{0, j})^2.\\
\end{equation}

In order to transform the first term, we observe that, $u$ and $v$ being two
$m\times n$ images

\begin{equation}
\begin{aligned}
\sum_{i=0}^{m-1}(u_{i, n-1}-u_{i, 0})(v_{i, n-1}-v_{i, 0})
&=\sum_{i=0}^{m-1}u_{i, 0}(v_{i, 0}-v_{i, n-1})
+\sum_{i=0}^{m-1}u_{i, n-1}(v_{i, n-1}-v_{i, 0})\\
&=\tfrac12 u\cdot(Q_1^\mathrm h\cdot v),
\end{aligned}
\label{eq:2}
\end{equation}

where we have introduced the linear operator $Q_1^\mathrm h$ defined as follows

\begin{equation}
\tfrac12(Q_1^\mathrm h\cdot u)_{ij}=
\begin{cases}
u_{i, 0}-u_{i, n-1} & \text{if }j=0,\\
u_{i, n-1}-u_{i, 0} & \text{if }j=n-1,\\
0                   & \text{otherwise}.
\end{cases}
\label{eq:3}
\end{equation}

From the left-hand side of Eq. \eqref{eq:2}, the linear operator $Q_1^\mathrm
h$ thus defined is obviously symmetric and positive. Besides, the first term in
Eq.  \eqref{eq:1} reads

\begin{equation*}
2\sum_{i=0}^{m-1}(p_{i, n-1}-p_{i, 0})^2=p\cdot Q_1^\mathrm h\cdot p.
\end{equation*}

Turning now to the second term in Eq. \eqref{eq:1}, we introduce the symmetric,
positive linear operator $Q_1^\mathrm v$ defined by

\begin{equation}
\tfrac12(Q_1^\mathrm v\cdot u)_{ij}=\begin{cases}
u_{0, j}-u_{m-1, j} & \text{if }i=0,\\
u_{m-1, j}-u_{0, j} & \text{if }i=m-1,\\
0                   & \text{otherwise},
\end{cases}
\label{eq:4}
\end{equation}

so that

\begin{equation*}
2\sum_{j=0}^{n-1}(p_{m-1, j}-p_{0, j})^2=p\cdot Q_1^\mathrm v\cdot p.
\end{equation*}

Gathering the above results and introducing the symmetric operator
$Q_1=Q_1^\mathrm h+Q_1^\mathrm v$, we finally find that
$E_\mathrm p(p)=p\cdot Q_1\cdot p$.

* Contribution of the smooth component <<smooth-contrib>>

The contribution to the total energy of the smooth component $s$ is defined by
Moisan ([[moisan2011:][2011]]) as follows (see also [[sb-blog-prev:][previous post]])

\begin{equation}
\label{eq:5}
E_\mathrm s'(s)=2\sum_{i=0}^{m-2}\sum_{j=0}^{n-1}(s_{i+1, j}-s_{i, j})^2
+2\sum_{i=0}^{m-1}\sum_{j=0}^{n-2}(s_{i, j+1}-s_{i, j})^2.
\end{equation}

The total energy is to be minimized over the space of zero-mean images $s$. It
will therefore be convenient to introduce the following modified energy

\begin{equation}
\label{eq:6}
E_\mathrm s(s)=E_\mathrm s'(s)+(\operatorname{mean}s)^2,
\end{equation}

so that $E_\mathrm s(s)=E_\mathrm s'(s)$ at the solution of the minimization
problem. In order to transform the first term in Eq. \eqref{eq:5}, we observe
that, $u$ and $v$ being two $m\times n$ images

\begin{equation}
\begin{aligned}[b]
&\sum_{i=0}^{m-2}\sum_{j=0}^{n-1}(u_{i+1, j}-u_{i, j})(v_{i+1, j}-v_{i, j})\\
={}&\sum_{i=0}^{m-2}\sum_{j=0}^{n-1}u_{i+1, j}(v_{i+1, j}-v_{i, j})
-\sum_{i=0}^{m-2}\sum_{j=0}^{n-1}u_{i, j}(v_{i+1, j}-v_{i, j})\\
={}&\sum_{i=1}^{m-1}\sum_{j=0}^{n-1}u_{i, j}(v_{i, j}-v_{i-1, j})
-\sum_{i=0}^{m-2}\sum_{j=0}^{n-1}u_{i, j}(v_{i+1, j}-v_{i, j})\\
={}&\sum_{i=1}^{m-2}\sum_{j=0}^{n-1}u_{i, j}(2v_{i, j}-v_{i-1, j}-v_{i+1,j})\\
&+\sum_{j=0}^{n-1}u_{m-1, j}(v_{m-1, j}-v_{m-2, j})
+\sum_{j=0}^{n-1}u_{0, j}(v_{0, j}-v_{1, j})\\
={}&\tfrac12 u\cdot(Q_2^\mathrm h\cdot v),
\end{aligned}
\label{eq:7}
\end{equation}

where we have introduced the linear operator $Q_2^\mathrm h$ defined as follows

\begin{equation}
\tfrac12(Q_2^\mathrm h\cdot u)_{i,j}=
\begin{cases}
u_{0, j}-u_{1, j}              & \text{if }i=0,\\
u_{m-1, j}-u_{m-2, j}          & \text{if }i=m-1,\\
2u_{i, j}-u_{i-1, j}-u_{i+1,j} & \text{otherwise}.
\end{cases}
\label{eq:8}
\end{equation}

From the left-hand side of Eq. \eqref{eq:7}, the linear operator
$Q_2^\mathrm h$ thus defined is obviously symmetric and positive. Besides, the
first term in Eq. \eqref{eq:5} reads

\begin{equation*}
2\sum_{i=0}^{m-2}\sum_{j=0}^{n-1}(s_{i+1, j}-s_{i, j})^2
=s\cdot Q_2^\mathrm h\cdot s.
\end{equation*}

Turning now to the second term in Eq. \eqref{eq:5}, we introduce the symmetric,
positive linear operator $Q_2^\mathrm v$ defined by

\begin{equation}
\tfrac12(Q_2^\mathrm v\cdot u)_{i,j}=
\begin{cases}
u_{i, 0}-u_{i, 1}              & \text{if }j=0,\\
u_{i, n-1}-u_{i, n-2}          & \text{if }j=n-1,\\
2u_{i, j}-u_{i, j-1}-u_{i,j+1} & \text{otherwise}.
\end{cases}
\label{eq:9}
\end{equation}

so that

\begin{equation*}
2\sum_{i=0}^{m-1}\sum_{j=0}^{n-2}(s_{i, j+1}-s_{i, j})^2
=s\cdot Q_2^\mathrm v\cdot s.
\end{equation*}

Finally

\begin{equation}
\begin{aligned}[b]
(\operatorname{mean}u)(\operatorname{mean}v)
&=\frac{\operatorname{mean}v}{mn}\sum_{i=0}^{m-1}\sum_{j=0}^{n-1}u_{i,j}
=\sum_{i=0}^{m-1}\sum_{j=0}^{n-1}u_{i,j}\times\frac{\operatorname{mean}v}{mn}
=\vec u\cdot(Q_2^\mathrm m\cdot v),
\end{aligned}
\label{eq:10}
\end{equation}

where we have introduced the symmetric, positive operator $Q_2^\mathrm m$
defined as follows

\begin{equation}
(Q_2^\mathrm m\cdot u)_{i,j}=\frac{\operatorname{mean} u}{mn}
=\frac1{m^2n^2}\sum_{i=0}^{m-1}\sum_{j=0}^{n-1}u_{i,j}.
\label{eq:11}
\end{equation}

Gathering the above results and introducing the symmetric, positive operator
$Q_2=Q_2^\mathrm h+Q_2^\mathrm v+Q_2^\mathrm m$, we finally find that
$E_\mathrm s(s)=s\cdot Q_2\cdot s$.

* Implementation of the operators /Q₁/ and /Q₂/

The operators $A$ and $B$ defined above are linear operators. They may in
principle be implemented as matrices. However, doing so would be a terrible
idea. First, because the matrix would be huge ($mn\times mn$ coefficients for a
$m\times n$ image), and second, because a new matrix would need to be created
each time we work with a different image.

Instead, we will adopt here a /matrix-free/ approach, where $A$ and $B$ are
implemented as =LinearOperator= from the =scipy.sparse.linalg= module (see
[[https://docs.scipy.org/doc/scipy-0.18.1/reference/generated/scipy.sparse.linalg.LinearOperator.html#scipy.sparse.linalg.LinearOperator][documentation]]). Essentially, what this means is that $A$ and $B$ are
/functions/ that perform the matrix-vector product. Often times, this is enough
to perform fairly complex linear algebra operations. In particular, solving
linear systems that involve $A$ and $B$ can then be done by means of
[[https://en.wikipedia.org/wiki/Iterative_method#Linear_systems][iterative linear solvers]], such as the [[https://en.wikipedia.org/wiki/Conjugate_gradient_method][conjugate gradient method]]. Interesting references on this topic are the book by Y. Saad:
[[https://doi.org/10.1137/1.9780898718003][Iterative Methods for Sparse Linear Systems]] and the book by Barrett /et al./:
[[http://epubs.siam.org/doi/book/10.1137/1.9781611971538][Templates for the Solution of Linear Systems: Building Blocks for Iterative Methods]] (also freely available [[http://www.netlib.org/templates/][here]]).

It should be noted that instances of =LinearOperator= (in the Scipy sense)
operate on 1D-vectors. Therefore, 2D images must be converted to 1D vectors
each time linear operators are to ben invoked. We will assume C-ordering in the
implementation below.

We first create the base class =ImageLinearOperator=, that defines linear
operators that operate on images. These operators store the shape of the image.

#+BEGIN_SRC ipython :exports results :results output code
  import inspect

  import moisan2011

  print(inspect.getsource(moisan2011.ImageLinearOperator))
#+END_SRC

#+RESULTS:
#+BEGIN_SRC ipython
class ImageLinearOperator(scipy.sparse.linalg.LinearOperator):
    """Linear operator that operate on images.

    This class defines a linear operator (in the SciPy sense) that
    operates on n-dimensional images, the shape of which is passed to
    the initializer

    >>> a = ImageLinearOperator(10, 5)
    >>> a.img_shape
    (10, 5)
    >>> a.shape
    (50, 50)

    SciPy linear operators operate on one-dimensional vectors: the
    methods _matvec and _adjoint implemented by each subclass must
    therefore first reshape the input array to a n-dimensional
    image. By convention, C-ordering will always be assumed.

        y = numpy.zeros_like(x)
        x2 = x.reshape(self.img_shape)
        y2 = y.reshape(self.img_shape)
        ......................
        # Operate on x2 and y2
        ......................
        return y

    Alternatively, developers may implement the method _apply that
    operates on n-dimensional images: the default implementation of
    _matvec calls this method on the input vector, suitably reshaped to
    a n-dimensional image.
    """
    def __init__(self, *args):
        self.img_shape = tuple(int(n) for n in args)
        n = np.product(self.img_shape)
        shape = (n, n)
        dtype = np.dtype(np.float64)
        super().__init__(dtype, shape)

    def _matvec(self, x):
        y = np.zeros_like(x)
        x2 = x.reshape(self.img_shape)
        y2 = y.reshape(self.img_shape)
        self.ddot(x2, y2)
        return y

    def _apply(x, y=None):
        """Apply this operator on the input image x.

        The shape of x must be self.img_shape. The returned array has
        same shape as x.

        If specified, the optional argument y must be an array of same
        shape as x. It is modified in-place, and a reference to y is
        returned.
        """
        raise NotImplementedError()

#+END_SRC

Then, implementation of the $Q_1$ operator is fairly simple.

#+BEGIN_SRC ipython :exports results :results output code
  import inspect

  import moisan2011

  print(inspect.getsource(moisan2011.OperatorQ1))
#+END_SRC

#+RESULTS:
#+BEGIN_SRC ipython
class OperatorQ1(ImageLinearOperator):
    u"""Implementation of Q₁ as a ``ImageLinearOperator``.

    Q₁ is defined by Eq. (9) of Moisan (2011)

        F(s) = (u-s)ᵀ·Q₁·(u-s)+sᵀ·Q₂·s,

    where F(s) is the function to be minimized, defined by Eq. (8)

        F(s) = E(u-s, s) + mean(s)².

    Image p = u-s must be passed as a 1-dimensional vector. Internally,
    it is reshaped to a two-dimensional image (the shape of which is
    passed to the initializer), **assuming C-ordering**.
    """
    def __init__(self, *args):
        super().__init__(*args)

    def _apply(self, x, y=None):
        if y is None:
            y = np.zeros_like(x)

        dx = 2.0*(x[:, 0]-x[:, -1])
        y[:, 0] = dx
        y[:, -1] = -dx

        dx = 2.0*(x[0, :]-x[-1, :])
        y[0, :] += dx
        y[-1, :] -= dx

        return y

    def _adjoint(self):
        return self

#+END_SRC

Note that $Q_1$ is symmetric: the =_adjoint= method simply returns =self=.
