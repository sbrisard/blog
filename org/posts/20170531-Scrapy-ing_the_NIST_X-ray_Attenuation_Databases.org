# -*- coding: utf-8; -*-
#+SETUPFILE: "../include/css-1.org"
#+TITLE: Scrapy-ing the NIST X-ray Attenuation Databases
#+DATE: [2017-05-31 Wed]

I am currently preparing with two other colleagues a review paper on
X-ray tomography of cementitious materials, for which I need to
retrieve tabulated values of the [[https://en.wikipedia.org/wiki/Mass_attenuation_coefficient#Mass_attenuation_coefficients_for_X-rays][X-ray mass attenuation coefficients]]
of all elements.

NIST provides such data (see [[https://www.nist.gov/pml/x-ray-mass-attenuation-coefficients][X-Ray Mass Attenuation Coefficients]] by
J. H. Hubbell and S. M. Seltzer). However, it does not come in the
form of simple files that can be downloaded. Rather, the values are
presented in nicely formatted HTML tables (see [[http://physics.nist.gov/PhysRefData/XrayMassCoef/ElemTab/z01.html][here]] for an example).

In this post, I set out to extract this data as a HDF5 table. Of
course, this looks like a job for [[https://scrapy.org/][Scrapy]]!

* First steps with Scrapy

 I am brand new to Scrapy, but found the excellent [[https://docs.scrapy.org/en/latest/][tutorial]] extremely
useful. If you use Miniconda from [[https://www.continuum.io/][Continuum Analytics]], then
installation of Scrapy is a very smooth procedure

#+BEGIN_EXAMPLE
conda create --name scrapy python=3 scrapy
#+END_EXAMPLE

which installs Scrapy in a new environment (called =scrapy).

* Downloading the table for one single element

In this section, we retrieve the data for the mass attenuation
coefficient of one single element. We start with the data for
hydrogen, which can be found [[http://physics.nist.gov/PhysRefData/XrayMassCoef/ElemTab/z01.html][here]]. Following the [[https://docs.scrapy.org/en/latest/intro/tutorial.html#extracting-data][Scrapy tutorial]], we
first use the Scrapy shell.

#+BEGIN_EXAMPLE
activate scrapy
scrapy shell "http://physics.nist.gov/PhysRefData/XrayMassCoef/ElemTab/z01.html"
#+END_EXAMPLE

Looking at the page source, it is observed that the table in ASCII
format is located within a =pre= tag. This suggests the following CSS
selector

#+BEGIN_SRC python
  out = response.css('pre').extract_first()
  print(out)
#+END_SRC

which produces the following abbreviated output

#+BEGIN_EXAMPLE
<pre>__________________________________

   <b>Energy</b><sub> </sub>       <i>µ</i>/<i>?</i>        <i>µ</i><sub>en</sub>/<i>?</i>
   <sup> </sup>(MeV)      (cm<sup>2</sup>/g)     (cm<sup>2</sup>/g)
__________________________________

 1.00000E-03  7.217E+00  6.820E+00
 1.50000E-03  2.148E+00  1.752E+00
 .................................
 1.50000E+01  2.539E-02  1.837E-02
 2.00000E+01  2.153E-02  1.606E-02
</pre>
#+END_EXAMPLE

This is already quite good. We now break the above output in lines,
eliminate the first six lines which correspond to the header, and
convert each row to floats.

#+BEGIN_SRC python
  lines = out.splitlines()
  table = [[float(x) for x in line.split()] for line in lines[6:-1]]
  print(table)
#+END_SRC

#+BEGIN_EXAMPLE
[[0.001, 7.217, 6.82], [0.0015, 2.148, 1.752],
..................................................,
[15.0, 0.02539, 0.01837], [20.0, 0.02153, 0.01606]]
#+END_EXAMPLE

… and we're done! Or?!? Let's what happens with [[http://physics.nist.gov/PhysRefData/XrayMassCoef/ElemTab/z13.html][Aluminum]].

#+BEGIN_EXAMPLE
activate scrapy
scrapy shell "http://physics.nist.gov/PhysRefData/XrayMassCoef/ElemTab/z13.html"
#+END_EXAMPLE

#+BEGIN_SRC python
  out = response.css('pre').extract_first()
  lines = out.splitlines()
  table = [[float(x) for x in line.split()] for line in lines[6:-1]]
#+END_SRC

This produces the following error

#+BEGIN_EXAMPLE
Traceback (most recent call last):
  File "<console>", line 1, in <module>
  File "<console>", line 1, in <listcomp>
  File "<console>", line 1, in <listcomp>
ValueError: could not convert string to float: 'K'
#+END_EXAMPLE

This has to do with the [[https://en.wikipedia.org/wiki/Absorption_edge][absorption edge]] of the element, which is
marked by a letter in the first column of the table, as shown below.

#+BEGIN_SRC python
  lines[9]
#+END_SRC

#+BEGIN_EXAMPLE
'K  1.55960E-03  3.957E+03  3.829E+03 '
#+END_EXAMPLE

So we need to skip the first character in each row. In fact, we can
safely skip the first three characters.

#+BEGIN_SRC python
  out = response.css('pre').extract_first()
  lines = out.splitlines()
  table = [[float(x) for x in line[3:].split()] for line in lines[6:-1]]
  print(table)
#+END_SRC

#+BEGIN_EXAMPLE
[[0.001, 1185.0, 1183.0], [0.0015, 402.2, 400.1],
..................................................,
[15.0, 0.02195, 0.01631], [20.0, 0.02168, 0.01633]]
#+END_EXAMPLE

… and the problem is solved!

* Downloading tables for all elements

All links follow the same pattern
=http://physics.nist.gov/PhysRefData/XrayMassCoef/ElemTab/zZZ.html=,
where ZZ is the [[https://en.wikipedia.org/wiki/Atomic_number][atomic number]]. So we only need to generate a list of
links in the =Spider=.

We start by creating a Scrapy project.

#+BEGIN_EXAMPLE
activate scrapy
scrapy startproject scrapymu
#+END_EXAMPLE

We then edit the =scrapymu/scrapymu/spiders/tables.py= file

#+BEGIN_SRC python
  import scrapy

  BASE_URL = 'http://physics.nist.gov/PhysRefData/XrayMassCoef'
  TABLE3_URL = '/'.join([BASE_URL, 'ElemTab/z{:02d}.html'])


  class Table3Spider(scrapy.Spider):
      name = 'table3'

      start_urls = [TABLE3_URL.format(z) for z in range(1, 93)]

      def parse(self, response):
          pre = response.css('pre').extract_first()
          lines = pre.splitlines()
          value = [[x for x in line[3:].split()] for line in lines[6:-1]]
          key = response.url.split('/')[-1].split('.')[0]
          yield {key: value}
#+END_SRC

This spider can be run as follows

#+BEGIN_EXAMPLE
scrapy crawl table3 -o table3.json
#+END_EXAMPLE

