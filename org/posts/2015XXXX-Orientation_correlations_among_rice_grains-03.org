# -*- coding: utf-8; -*-
#+TITLE: Orientation correlations among rice grains, part 3: binning -- The Pythonic way
#+DATE: [2015-03-10 Tue]
#+PROPERTY: header-args:python :results value verbatim :session :exports both

The full reconstructed image is a 1747×1751×688 stack, and we do not need such fine images to resolve the rice grains. In order to reduce the computation times, the images will first be /binned/, that is each set of --say-- 4×4×4 voxels will be replaced with a unique voxel, with average gray value. This is illustrated below (see Fig. [[fig:1]]).

3D binning would usually require 3 uggly nested loops. There is, however, a much more pythonic way. This is the topic of the present post.

#+CAPTION: The original (left) and binned (right) images. Each pixel in the right image is the average of 4^3@@html:&thinsp;@@=@@html:&thinsp;@@64 voxels. As a result, the binned image is far less noisy than the original one.
#+NAME: fig:1
#+ATTR_HTML: :width 90%
file:./2015XXXX-Orientation_correlations_among_rice_grains-03/original_vs_binned.png

* Zen of NumPy

You probably have all heard of Tim Peters' /Zen of Python/, which you can display in the Python console through the command =import this=. It is reproduced below, just for fun.

#+BEGIN_VERSE
The Zen of Python, by Tim Peters

Beautiful is better than ugly.
Explicit is better than implicit.
Simple is better than complex.
Complex is better than complicated.
Flat is better than nested.
Sparse is better than dense.
Readability counts.
Special cases aren't special enough to break the rules.
Although practicality beats purity.
Errors should never pass silently.
Unless explicitly silenced.
In the face of ambiguity, refuse the temptation to guess.
There should be one-- and preferably only one --obvious way to do it.
Although that way may not be obvious at first unless you're Dutch.
Now is better than never.
Although never is often better than *right* now.
If the implementation is hard to explain, it's a bad idea.
If the implementation is easy to explain, it may be a good idea.
Namespaces are one honking great idea -- let's do more of those!
#+END_VERSE

A few years ago, [[https://plus.google.com/111231464998965388525/about][Travis Oliphant]], who is the author of NumPy (but also CEO of [[http://www.continuum.io/][Continuum Analytics]], which provides [[https://store.continuum.io/cshop/anaconda/][Anaconda]]), wrote a post called /[[http://technicaldiscovery.blogspot.fr/2010/11/zen-of-numpy.html][Zen of NumPy]]/, in which he came up with the following points

#+BEGIN_VERSE
Strided is better than scattered
Contiguous is better than strided
Descriptive is better than imperative (use data-types)
Array-oriented is often better than object-oriented
Broadcasting is a great idea -- use where possible
Vectorized is better than an explicit loop
Unless it’s complicated --- then use numexpr, weave, or Cython
Think in higher dimensions
#+END_VERSE

We will be particularly interested in the last point: "think in higher dimensions"; this, and the =numpy.lib.stride_tricks.as_strided()= function are the crux of the present post.

* Binning a 2D array: using loops

We eventually want to perform binning on a 3D array (a stack of 2D slices). But, for the sake of illustration, the method will be demonstrated on a 2D array. We must first generate the data

#+BEGIN_SRC python
  import numpy as np

  np.random.seed(20150324)
  a = np.random.rand(15, 9)

  'Shape of original array: {}'.format(a.shape)
#+END_SRC

#+RESULTS:
: Shape of original array: (15, 9)

Note that the shape of the =a= (the array to be binned) is purposely not a multiple of 4! Also note that, in order to make tests fully reproducible, it is good practice to seed the random generator manually.

We then create the empty, reference array =actual=, which is to receive the binned array (computed through explicit loops)

#+BEGIN_SRC python
  bin_size = 4
  shape = tuple(n // bin_size for n in a.shape)
  expected = np.zeros(shape, dtype=np.float64)

  'Shape of binned array: {}'.format(shape)
#+END_SRC

#+RESULTS:
: Shape of binned array: (3, 2)

Finally, we loop over all cells to compute the binned array

#+BEGIN_SRC python
  for j0 in range(expected.shape[0]):
      for j2 in range(bin_size):
          i0 = j0 * bin_size + j2
          for j1 in range(expected.shape[1]):
              for j3 in range(bin_size):
                  i1 = j1 * bin_size + j3
                  expected[j0, j1] += a[i0, i1]

  expected /= (bin_size * bin_size)
  expected
#+END_SRC

#+RESULTS:
: [[ 0.55571299  0.56719206]
:  [ 0.48390604  0.5127349 ]
:  [ 0.5167703   0.53772563]]

That was tedious, wasn't it? Now, for the more elegant stuff.

* Binning a 2D array: thinking in higher dimensions

The present approach works only for strided arrays. =numpy.ndarray.strides= is defined in the [[http://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.strides.html][NumPy documentation]] as follows

#+BEGIN_QUOTE
Tuple of bytes to step in each dimension when traversing an array. The byte offset of element (=i[0], i[1], ..., i[n]=) in an array =a= is:
#+BEGIN_EXAMPLE
offset = sum(np.array(i) * a.strides)
#+END_EXAMPLE
#+END_QUOTE

Let's look at the strides of our array =a=

#+BEGIN_SRC python
  a.strides
#+END_SRC

#+RESULTS:
: (72, 8)

In other words, the offset (in bytes) of element =(i0, i1)= is =s0 * i0 + s1 * i1=, where =(s0, s1)= is =a.strides=.

#+BEGIN_SRC python
  from numpy.lib.stride_tricks import as_strided

  new_shape = tuple(n // bin_size for n in a.shape) + (bin_size, bin_size)
  new_strides = tuple(s * bin_size for s in a.strides) + a.strides
  aa = as_strided(a, shape=new_shape, strides=new_strides)
  actual = np.mean(aa, axis=(2, 3))

  actual
#+END_SRC

#+RESULTS:
: [[ 0.52302399  0.53382782]
:  [ 0.45544097  0.48257402]
:  [ 0.48637204  0.50609471]]


Let's check that =actual= and =expected= are actually equal

#+BEGIN_SRC python
  np.sqrt(np.sum((actual - expected)**2))
#+END_SRC

#+RESULTS:
: 1.75541673429e-16

# Local Variables:
# org-confirm-babel-evaluate: nil
# End:
