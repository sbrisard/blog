#+TITLE: Review of "Parallel Programming with Python"
#+SETUPFILE: "../header.org"
#+SETUPFILE: "../header-1.org"
#+INCLUDE: "../navbar-1.org"

I have again recently been offered by [[http://www.packtpub.com/][Packt Publishing]] to review one of their books, entitled [[http://goo.gl/oMUSLW][Parallel Programming with Python]] (by Jan Palach).@@html:<!-- more -->@@

For a long time, programmers have been relying exclusively on [[http://en.wikipedia.org/wiki/Moore%27s_law][Moore's law]] to resolve their performance issues. In other words, they trusted the fact that the CPU frequency would increase, making their program faster /without changing one single line/. Today however, [[http://www.gotw.ca/publications/concurrency-ddj.htm]["the free lunch is over"]], as already argued by Herb Sutter in 2004. The frequency of CPUs tends to stagnate, while the number of cores in even the cheapest laptop has increased. For Sutter, the immediate consequence is: "applications will increasingly need to be concurrent if they want to fully exploit CPU throughput gains".

Python is no exception to this paradigm change and this book introduces several ways to go parallel with Python using the standard library modules [[https://docs.python.org/3/library/threading.html][threading]], [[https://docs.python.org/3/library/multiprocessing.html][multiprocessing]] and [[https://docs.python.org/3/library/asyncio.html][asyncio]], and the third-party modules [[http://parallelpython.com][Parallel Python]] and [[http://celeryproject.org][Celery]]. This is quite an impressive list for such a short book, but I personally think that [[http://ipython.org/ipython-doc/dev/parallel/][IPython.parallel]] and [[https://bitbucket.org/mpi4py/mpi4py/][mpi4py]] (both quite popular in scientific computing) should have made it into this book.

Parallel programming in Python is no trivial task because of the [[https://wiki.python.org/moin/GlobalInterpreterLock][Global Interpreter Lock (GIL)]] which "prevents multiple native threads from executing Python bytecodes at once". While this issue is briefly mentioned in this book (in a section called "Taking Care of Python GIL"), I think that the author should have made it clearer which modules suffer from this limitation, and which don't. For example, the following statement (which can be found page 30) is far too vague

#+BEGIN_QUOTE
Within the Python programming language, the use of CPU-bound threads may harm performance of the application due to GIL.
#+END_QUOTE

"may harm performance"? Could you be more precise, please? The answer can be found in the module's [[https://docs.python.org/3/library/threading.html][official documentation]]

#+BEGIN_QUOTE
CPython implementation detail: In CPython, due to the /Global Interpreter Lock/, only one thread can execute Python code at once (even though certain performance-oriented libraries might overcome this limitation). If you want your application to make better use of the computational resources of multi-core machines, you are advised to use =multiprocessing= or =concurrent.futures.ProcessPoolExecutor=. However, threading is still an appropriate model if you want to run multiple I/O-bound tasks simultaneously.
#+END_QUOTE

So the truth is that "may harm" should really read "does harm". To be fair, a much more clear-cut statement can be found page 94

#+BEGIN_QUOTE
A way to solve this problem is delegating a blocking task to =ThreadPoolExecutor= (remember this works well if the processing is I/O bound; if it is CPU-bound, use =ProcessPoolExecutor=).
#+END_QUOTE

The book starts with two introductory chapters, in which the reader will find useful material. *Chapter 1* presents a historical background, defines various forms of parallelization as well as the most common pitfalls of parallel programming (deadlock, starvation, race condition). *Chapter 2* reviews a few parallelization strategies.

In *chapter 3*, the author presents two simple problems which will be used in the remainder of the book to illustrate the use of the various modules I mentioned above. I find the idea of reusing the same two examples over and over again quite interesting, as it makes it easier to the reader to understand the differences and similarities between these modules. Besides, the two examples are simple, and so is their parallel implementation. Maybe these two problems are too simple, though. Indeed, both are [[http://en.wikipedia.org/wiki/Embarrassingly_parallel][embarrasingly parallel problems]], for which very little communication is required (besides scattering the data at the beginning and gathering the results at the end). In such a favorable situation, the potential "parallel programming problems" listed in chapter 1 are simply swept under the rug, which is probably better for an introductory book on parallel programming.

In *Chapters 4, 5, 6, 7 and 8*, these two problems are implemented using the following modules in turn: =threading=, =multiprocessing=, =pp=, =celery= and =asyncio=. Of course, the API of these modules is not (cannot be) described in detail in such a short book: only the most elementary classes and functions are described. So be ready to dive into the API documentations after reading this book! It should be mentioned that the chapters on =celery= and =asyncio= (new in Python 3.4) provide more details, and are very enjoyable. I do think that a closing comparison between all these modules is clearly missing.

To conclude, I would recommend this book to those of you who are willing to go parallel in Python, but do not know where to start. This book usefully lists various options and provides the keys to each of those. Happy reading!
